\documentclass[]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage[]{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\PassOptionsToPackage{hyphens}{url} % url is loaded by hyperref
\usepackage[unicode=true]{hyperref}
\hypersetup{
            pdftitle={Material de Clase},
            pdfauthor={Ricardo Palma},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage[margin=1in]{geometry}
\usepackage[]{biblatex}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\usepackage{longtable,booktabs}
% Fix footnotes in tables (requires footnote package)
\IfFileExists{footnote.sty}{\usepackage{footnote}\makesavenoteenv{long table}}{}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

% set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother

\usepackage{booktabs}
\usepackage{amsthm}
\makeatletter
\def\thm@space@setup{%
  \thm@preskip=8pt plus 2pt minus 4pt
  \thm@postskip=\thm@preskip
}
\makeatother

\title{Material de Clase}
\author{Ricardo Palma}
\date{6 de septiembre de 2020}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{2}
\tableofcontents
}
\section*{Prefacio}\label{prefacio}
\addcontentsline{toc}{section}{Prefacio}

Di3 Doctorado Interinsititucional en Ingeniería Industrial

\begin{itemize}
\tightlist
\item
  Universidad Nacional de Cuyo.
\item
  Universidad Nacional de Misiones (Overá)
\item
  Universidad Nacional de Jujuy
\item
  Universidad Nacional de Salta
\item
  Universidad Nacional de La Rioja
\item
  Universidad Nacional de Tucuman
\end{itemize}

\section{Prerequisitos para el curso}\label{prerequisitos-para-el-curso}

Para realizar este curso debes tener más pasión que vocación. Este curso
está pensado para interesados en el doctorado en ingeniería industrial
Di3

No necesitas saber programar, repito \textbf{NO NECESITAS} !!!

\begin{figure}
\centering
\includegraphics{data-science.png}
\caption{Esto es programar}
\end{figure}

Pero si has hecho esto que aparece en la figura alguna vez en tu vida,
no te preocupes \ldots{} Has programado sin saber que esto tan simple es
programar !!!

Lo realmente complicado es que vas ha tener que instalar algo de
sofrware libre y tener algo de espacio en el disco para manejar datasets
un poco aparatodos. Creo realmente que este es un requisito más
complicado que el de saber programar.

Utilizaremos a lo largo del curso el lenguaje R-Cran. Pero como es un
tanto árido para escribir nos valdremos de otro pargrama (del tipo que
se denomina IDE) llamado R-Studio. R-Studio es un Integratede
Development Envirnment o Entorno de Desarrollo Integrado que facilita
mucho jugar con los datos.

La secuencia de instalación es :

1 - Instalar R-Cran que puedes bajar de
\url{https://cran.r-project.org/}

2 - Instalar luego R-Studio que puedes bajar
\url{https://rstudio.com/products/rstudio/download/}

Elije la versión gratuita , a menos que te estén sobrando los dólares y
quieras pagar una liencia que no es muy cara.

Por favor sigue el oden de isntalación que indicamos.

\begin{verbatim}
        Existe un paquete para usar R-Cran desde Excel 
        (Aka usar comando de R dentro de Excel, pero hablaremos de esto en clase).
\end{verbatim}

Primero, debes importar tus datos hacia R. Típicamente, esto implica
tomar datos que están guardados en un archivo, base de datos o API y
cargarlos como data frame en R. Si no puedes llevar tus datos a R, no
puedes hacer ciencia de datos con él.

Una vez que has importado los datos, es una buena idea ordenarlos.
Ordenar los datos significa guardarlos de una manera consistente que
haga coincidir la semántica del set de datos con la manera en que está
guardado. En definitiva, cuando tus datos están ordenados, cada columna
es una variable y cada fila una observación. Tener datos ordenados es
importante porque si su estructura es consistente, puedes enfocar tus
esfuerzos en las preguntas sobre los datos y no en luchar para que estos
tengan la forma necesaria para diferentes funciones.

Cuando tus datos están ordenados, un primer paso suele ser
transformarlos. La transformación implica reducir las observaciones a
aquellas que sean de interés (como todas las personas de una ciudad o
todos los datos del último año), crear nuevas variables que sean
funciones de variables ya existentes (como calcular la rapidez a partir
de la velocidad y el tiempo) y calcular una serie de estadísticos de
resumen (como recuentos y medias). Juntos, a ordenar y transformar, se
les llama manejar o domar los datos, porque hacer que estos tengan la
forma con la que es natural trabajarlos, suele sentirse como una lucha.

Una vez que tienes los datos ordenados con las variables que necesitas,
hay dos principales fuentes generadoras de conocimiento: la
visualización y el modelado. Ambas tienen fortalezas y debilidades
complementarias, por lo que cualquier análisis real iterará entre ellas
varias veces.

La visualización es una actividad humana fundamental. Una buena
visualización te mostrará cosas que no esperabas o hará surgir nuevas
preguntas acerca de los datos. También puede darte pistas acerca de si
estás haciendo las preguntas equivocadas o si necesitas recolectar datos
diferentes. Las visualizaciones pueden sorprenderte, pero no escalan
particularmente bien, ya que requieren ser interpretadas por una
persona.

Los modelos son herramientas complementarias a la visualización. Una vez
que tus preguntas son lo suficientemente precisas, puedes utilizar un
modelo para responderlas. Los modelos son herramientas matemáticas o
computacionales, por lo que generalmente escalan bien. Incluso cuando no
lo hacen, resulta más económico comprar más computadores que comprar más
cerebros. Sin embargo, cada modelo tiene supuestos y, debido a su propia
naturaleza, un modelo no puede cuestionar sus propios supuestos. Esto
significa que un modelo, por definición, no puede sorprenderte.

El último paso de la ciencia de datos es la comunicación, una parte
crítica de cualquier proyecto de análisis de datos. No importa qué tan
bien tus modelos y visualizaciones te hayan permitido entender tus
datos, a menos que también puedas comunicar esos resultados a otras
personas.

Alrededor de todas estas herramientas se encuentra la programación. La
programación es una herramienta transversal que usarás en todas las
partes de tu proyecto. No necesitas ser una personas experta en
programación para hacer ciencia de datos, pero aprender más sobre ella
es una gran ventaja porque te permite automatizar tareas recurrentes y
resolver problemas con mayor facilidad.

En cualquier proyecto de ciencia de datos tendrás que ocupar estas
herramientas, pero en muchos casos estas no serán suficientes. Hay un
regla aproximada de 80-20 en juego: puedes enfrentar alrededor del 80 \%
de cualquier proyecto usando las herramientas que aprenderás en este
curso, pero necesitarás utilizar otras para abordar el 20 \% restante. A
lo largo del curso te iremos señalando recursos donde puedes aprender
más.

\subsection{Primer referencia biblográfica que puede
ayudarte.}\label{primer-referencia-biblogruxe1fica-que-puede-ayudarte.}

\subsubsection{R para Ciencia de Datos}\label{r-para-ciencia-de-datos}

Garrett Grolemund Hadley Wickham

Este es el Libro Web de la versión en español de ``R for Data Science'',
de Hadley Wickham y Garrett Grolemund. Este texto te enseñará cómo hacer
ciencia de datos con R: aprenderás a importar datos, llevarlos a la
estructura más conveniente, transformarlos, visualizarlos y modelarlos.
Así podrás poner en pŕactica las habilidades necesarias para hacer
ciencia de datos. Tal como los químicos aprenden a limpiar tubos de
ensayo y ordenar un laboratorio, aprenderás a limpiar datos y crear
gráficos--- junto a muchas otras habilidades que permiten que la ciencia
de datos tenga lugar. En este libro encontrarás las mejores prácticas
para desarrollar dichas tareas usando R. También aprenderás a usar la
gramática de gráficos, programación letrada e investigación reproducible
para ahorrar tiempo. Además, aprenderás a manejar recursos cognitivos
para facilitar el hacer descubrimientos al momento de manipular,
visualizar y explorar datos.

Link al libro web \url{https://es.r4ds.hadley.nz/index.html}

Citas correctamente realizada \autocite{wickham2018r}

\section{Introduction}\label{introduction}

This chapter is an overview of the methods that we propose to solve an
\textbf{important problem}.

\section{Analítica de Datos}\label{Encuentro_1}

\subsection{Teoría}\label{teoruxeda}

\subsubsection{Bases de la analítica de
datos}\label{bases-de-la-analuxedtica-de-datos}

Habitualmente en el terreno de las ingenierías, especialmente en las
ingenierías generalistas, como la mecatrónica y la industrial, hay una
serie de pasos que guían el paso de un profesional junior a senior. Este
paso intermedio al que nos referimos es el de un profesional que pasa de
las estapas operativas o de planeamiento táctico al de una persona con
mucha experiencia es ese terreno que se transforma de supervisor de un
área limitada a ANALISTA.

La principal característica de este profesional es que ha logrado,
merced a su experiencia en varios proyectos o años de planeación y
supervisión el talento para lograr una abstracción que le permitiría en
teoría saltar del campo disciplinar en el que se formó para instalarse
en otro distinto y ser exitoso sin pasar por la experimentación y
experiencia.

Hemos conocido a muchos ingenieros y profesionales del terreno
industrial que, por ejemplo tuvieron unos 5 a 10 años en el área del
retail o del supermrecadismo en Argentina y saltaron a ser analistas en
el terreno de la industria automotriz en Brasil. ¿Cómo es esto posible?

La respuesta más simple para entender esta situación es que se trata de
procesos (o fenómenos) homólogos. Vale decir los modelos y eurísticas
del retail en la preparación de pedidos y forecasting son los mismos que
rigen el planeamiento de la producción de una línea automotríz.

Pensemos, con la ley de Ohm es casi natural para los ingenieros explicar
fenómenos sociales o el mismo calentamiento global.

Un analista es capaz de observar un comportamiento e intuir en
determinadas circunstancias tal o cual modelo no es aplicable a una
situación coyuntural.

A modo de ejemplo casi ningún analista en la cadena de suministros
aplicaría en situación de pandemia el modelo de Wilson para determinar
el nivel de inventario o el tamaño de lote.

Existen analistas ``intuitivos'' que saben capitalizar sus experiencias
previas, pero este tiempo de los artesanos paa el análisis cada día se
torna menos creible y los verdaderamente exitosos han cambiado el
instinto por marcos teóricos formales. En tal sentido la inteligencia
artificial ha salido en ayuda del analista y como ella otros marcos
formales han conformado este campo disciplinar emergente que es el que
llamamos analítica de datos.

Existen al menos tres profesionales que integran los equipos del team de
la analítica de datos.

\begin{itemize}
\tightlist
\item
  Data Engineer
\item
  Data Scientific
\item
  Data worker o seeker
\item
  Pure Data Analyst
\item
  Draftsman
\end{itemize}

Todos son importantes en un equipo, pero ninguno es imprescindible. En
el sector PyME de LAC (Latino América y Caribe) no es extraño que estos
equipos se reduzcan a límite de ser equipos de una sola persona, que
además comercializan, compran materia prima, atienden los conflictos
familiares de los dueños de la empresa, pagan sueldos e impuestos y
barren. Todo sea por mantener la empresa en funcionamiento. Me olvidaba
, si queda tiempo hacen de advisor con la analítica de datos.

La Analítica de Datos (Data Analysis, o DA) es la ciencia que examina
datos en bruto con el propósito de sacar conclusiones sobre la
información. El análisis de datos es usado en varias industrias para
permitir que las compañías y las organizaciones \emph{tomen mejores
decisiones} empresariales y también es usado en las ciencias para
verificar o reprobar modelos o teorías existentes. El análisis de datos
se distingue de la extracción de datos por su alcance, su propósito y su
enfoque sobre el análisis. Los extractores de datos clasifican inmensos
conjuntos de datos usando software sofisticado para identificar patrones
no descubiertos y establecer relaciones escondidas. El análisis de datos
se centra en la inferencia, el proceso de derivar una conclusión
basándose solamente en lo que conoce el investigador y fuertemente
soportado por la estadística.

\begin{itemize}
\tightlist
\item
  Revisión de las herramientas de software y hardware disponibles
\item
  Georeferenciación y exploración georeferenciada de datos y
  bibliometría
\item
  Modelos basados en redes neuronales y su entrenamiento
\item
  Crítica de la KDNN con el uso de Big-Data
\end{itemize}

\subsection{Tecnologías}\label{tecnologuxedas}

\begin{itemize}
\tightlist
\item
  Soluciones propuesta con el uso de CUDA (uso de GPU en lugar de CPU)
\item
  Uso de la biblioteca Neuralnet y NeuralNetTools.
\item
  Uso de las bibliotecas Serial Time Análisis y Finance Econometics,
  diferencias entre las predicciones de ambas tecnologías
\end{itemize}

\subsection{Casos de estudio para el aula
virtual}\label{casos-de-estudio-para-el-aula-virtual}

Caso de Estudio -- El éxitoso caso de la industria del vino en Nueva
Zelanda durante la pandemia Caso de Estudio -- El INV y el sector
vitivinícola de Mendoza, hacia una nueva explosión del consumo de vinos
de alta gama como consecuencia de la cuarentena.

You can label chapter and section titles using \texttt{\{\#label\}}
after them, e.g., we can reference Chapter \ref{intro}. If you do not
manually label them, there will be automatic labels anyway, e.g.,
Chapter \ref{methods}.

Figures and tables with captions will be placed in \texttt{figure} and
\texttt{table} environments, respectively.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{par}\NormalTok{(}\DataTypeTok{mar =} \KeywordTok{c}\NormalTok{(}\DecValTok{4}\NormalTok{, }\DecValTok{4}\NormalTok{, .}\DecValTok{1}\NormalTok{, .}\DecValTok{1}\NormalTok{))}
\KeywordTok{plot}\NormalTok{(pressure, }\DataTypeTok{type =} \StringTok{'b'}\NormalTok{, }\DataTypeTok{pch =} \DecValTok{19}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{_main_files/figure-latex/nice-fig-1} 

}

\caption{Here is a nice figure!}\label{fig:nice-fig}
\end{figure}

Reference a figure by its code chunk label with the \texttt{fig:}
prefix, e.g., see Figure \ref{fig:nice-fig}. Similarly, you can
reference tables generated from \texttt{knitr::kable()}, e.g., see Table
\ref{tab:nice-tab}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(}
  \KeywordTok{head}\NormalTok{(iris, }\DecValTok{20}\NormalTok{), }\DataTypeTok{caption =} \StringTok{'Here is a nice table!'}\NormalTok{,}
  \DataTypeTok{booktabs =} \OtherTok{TRUE}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:nice-tab}Here is a nice table!}
\centering
\begin{tabular}[t]{rrrrl}
\toprule
Sepal.Length & Sepal.Width & Petal.Length & Petal.Width & Species\\
\midrule
5.1 & 3.5 & 1.4 & 0.2 & setosa\\
4.9 & 3.0 & 1.4 & 0.2 & setosa\\
4.7 & 3.2 & 1.3 & 0.2 & setosa\\
4.6 & 3.1 & 1.5 & 0.2 & setosa\\
5.0 & 3.6 & 1.4 & 0.2 & setosa\\
\addlinespace
5.4 & 3.9 & 1.7 & 0.4 & setosa\\
4.6 & 3.4 & 1.4 & 0.3 & setosa\\
5.0 & 3.4 & 1.5 & 0.2 & setosa\\
4.4 & 2.9 & 1.4 & 0.2 & setosa\\
4.9 & 3.1 & 1.5 & 0.1 & setosa\\
\addlinespace
5.4 & 3.7 & 1.5 & 0.2 & setosa\\
4.8 & 3.4 & 1.6 & 0.2 & setosa\\
4.8 & 3.0 & 1.4 & 0.1 & setosa\\
4.3 & 3.0 & 1.1 & 0.1 & setosa\\
5.8 & 4.0 & 1.2 & 0.2 & setosa\\
\addlinespace
5.7 & 4.4 & 1.5 & 0.4 & setosa\\
5.4 & 3.9 & 1.3 & 0.4 & setosa\\
5.1 & 3.5 & 1.4 & 0.3 & setosa\\
5.7 & 3.8 & 1.7 & 0.3 & setosa\\
5.1 & 3.8 & 1.5 & 0.3 & setosa\\
\bottomrule
\end{tabular}
\end{table}

You can write citations, too. For example, we are using the
\textbf{bookdown} package \autocite{R-bookdown} in this sample book,
which was built on top of R Markdown and \textbf{knitr}
\autocite{xie2015}.

\section{Literature}\label{literature}

Here is a review of existing methods.

\section{Bibliografía}\label{bibliografuxeda}

Estas referencias bibliográfica serán de utilidad en el curso

\section{Methods}\label{methods}

We describe our methods in this chapter.

\section{Métodos}\label{muxe9todos}

Métodos Utilizados en los trabajos

\section{Aplicaciones}\label{aplicaciones}

Casos de estudios

\subsection{El caso de Nuevazelanda de la industria del
vino}\label{el-caso-de-nuevazelanda-de-la-industria-del-vino}

\subsection{¿Que hace el INV en
Argentina}\label{que-hace-el-inv-en-argentina}

\section{Applications}\label{applications}

Some \emph{significant} applications are demonstrated in this chapter.

\subsection{Example one}\label{example-one}

\subsection{Example two}\label{example-two}

\section{Final Words}\label{final-words}

We have finished a nice book.

\section{Datasets}\label{datasets}

Set de Datos y Métodos de Depuración

\subsection{R Markdown}\label{r-markdown}

This is an R Markdown document. Markdown is a simple formatting syntax
for authoring HTML, PDF, and MS Word documents. For more details on
using R Markdown see \url{http://rmarkdown.rstudio.com}.

When you click the \textbf{Knit} button a document will be generated
that includes both content as well as the output of any embedded R code
chunks within the document. You can embed an R code chunk like this:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summary}\NormalTok{(cars)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      speed           dist       
##  Min.   : 4.0   Min.   :  2.00  
##  1st Qu.:12.0   1st Qu.: 26.00  
##  Median :15.0   Median : 36.00  
##  Mean   :15.4   Mean   : 42.98  
##  3rd Qu.:19.0   3rd Qu.: 56.00  
##  Max.   :25.0   Max.   :120.00
\end{verbatim}

\subsection{Including Plots}\label{including-plots}

You can also embed plots, for example:

\includegraphics{_main_files/figure-latex/pressure-1.pdf}

Note that the \texttt{echo\ =\ FALSE} parameter was added to the code
chunk to prevent printing of the R code that generated the plot.

\printbibliography

\end{document}
